from typing import Optional, Union
from PIL import Image
import os
import structlog
import requests
import threading
import time
import queue
from datetime import datetime
import numpy as np

from mobileclaw.utils.interface import UniInterface

logger = structlog.get_logger(__name__)

class DeviceControllerBase(UniInterface):
    def __init__(self, agent, device_name: str, device_id: str):
        super().__init__(agent)
        self._tag = 'device'
        self.device_bound = None
        self.device_name = device_name
        self.device_id = device_id

        self.width = 0
        self.height = 0
        
        # Recording state management
        self.recording_active = False
        self.recording_thread = None
        self.recording_frames = []
        self.recording_frame_queue = queue.Queue(maxsize=100)  # Limit queue size to prevent memory overflow
        self.recording_start_time = None
        self.recording_stop_time = None
        self.recording_stop_requested = False
        self.recording_output_path = None
        self.recording_metadata = {}  # Store recording metadata
        
        # GUI action recording state
        self.recording_action_timeline = []  # Store action events during recording
        self.recording_frame_actions = {}      # Map frame_number -> action_events
        self.recording_action_counter = 0      # Unique action identifier

    def __str__(self) -> str:
        return f"Device Interface: {self.device_name}"

    def execute_task(self, task: str, knowledge='', max_steps: int = 20, keep_recent_images: int = 3):
        """
        Execute a device control task using iterative LLM-generated Python code.

        Args:
            task: Task description (e.g., "Navigate to settings and enable dark mode")
            max_steps: Maximum number of steps to execute
            keep_recent_images: Number of recent images to keep in context (default: 3)

        Returns:
            list: Results collected during execution
        """
        import re
        import base64
        from io import BytesIO

        # Initialize notes list (acts as actions_and_results for logging)
        notes = []
        results = []
        actions_and_results = []

        # Get device type
        from mobileclaw.device.computer import ComputerDeviceBase
        from mobileclaw.device.browser import BrowserDeviceController
        if isinstance(self, ComputerDeviceBase):
            device_type = 'computer'
            task_tag = 'ğŸ’»'
        elif isinstance(self, BrowserDeviceController):
            device_type = 'browser'
            task_tag = 'ğŸŒ'
        else:
            device_type = 'phone'
            task_tag = 'ğŸ“±'

        # Log and report task start
        logger.info(f"ğŸš€ Starting device task: {task}")
        self.agent._log_and_report(f'Start device task: {task}', actions_and_results, task_tag=task_tag)

        for step in range(max_steps):
            # Pause if a message is being handled
            if hasattr(self.agent, '_message_pause_event'):
                self.agent._message_pause_event.wait()

            # Take screenshot
            screenshot = self.take_screenshot()

            # Convert screenshot to base64
            img_byte_arr = BytesIO()
            screenshot.save(img_byte_arr, format='PNG')
            img_bytes = img_byte_arr.getvalue()
            screenshot_base64 = base64.b64encode(img_bytes).decode('utf-8')
            img_byte_arr.close()

            # Extract images (previous screenshots and noted images) from actions_and_results
            images = []
            for item in actions_and_results:
                if isinstance(item, tuple) and len(item) == 2:
                    # This is an image tuple (path, base64)
                    images.append(item)

            # Keep only the most recent N images to limit context size
            if keep_recent_images > 0 and len(images) > keep_recent_images:
                images = images[-keep_recent_images:]

            # Get agent context information for this step
            agent_info = self.agent.get_agent_info()

            # Prepare params for device_use_step
            if len(actions_and_results) > self.agent.actions_and_results_max_len:
                actions_and_results = actions_and_results[-self.agent.actions_and_results_max_len:]
            params = {
                'task': task,
                'knowledge': knowledge,
                'actions_and_results': actions_and_results,
                'device_type': device_type,
                'current_screen': screenshot_base64,
                'images': images,
                'agent_info': agent_info
            }

            # Call device_use_step API
            thought, code = self.agent.fm.call_func('device_use_step', params)

            # Store screenshot in actions_and_results for history
            # Format: (path, base64) tuple - path can be descriptive string
            screenshot_path = f"previous_screenshot_step_{step}.png"
            actions_and_results.append((screenshot_path, screenshot_base64))

            # Add thought to results
            if thought:
                # self.agent.user.notify_thought(thought)
                self.agent._log_and_report(f'Step {step} Thought: {thought}', actions_and_results, task_tag=task_tag)

            # Stop if no code generated
            if not code:
                warning_msg = f"Step {step} Error: No code parsed from the response. Perhaps forgot to wrap code in code block?"
                logger.warning(warning_msg)
                self.agent._log_and_report(warning_msg, actions_and_results, task_tag=task_tag)
                continue # break

            self.agent._log_and_report(f'Step {step} Action:\n```\n{code}\n```', actions_and_results, task_tag=task_tag)

            # Execute the code
            try:
                # Create DeviceAPI instance for execution with notes, results, and actions_and_results
                device_api = self._create_device_api_for_execution(notes, results, actions_and_results)

                # Create execution environment
                exec_globals = {
                    'device': device_api,
                }

                # Execute the generated code
                exec(code, exec_globals)

                # Check task status
                task_status = exec_globals.get('task_status', 'ongoing')
                if task_status != 'ongoing':
                    logger.info(f"âœ… Task status: {task_status}")
                    self.agent._log_and_report(f'Task status: {task_status}', actions_and_results, task_tag=task_tag)
                    break

            except Exception as e:
                error_msg = f"Error: step {step} was failed - {e}"
                logger.error(error_msg)
                results.append(f"{error_msg}")
                self.agent._log_and_report(error_msg, actions_and_results, task_tag=task_tag)
                continue # NOTE: decide between break or continue

            # Sleep between steps
            self.agent.sleep(0.5)
        if step + 1 > max_steps:
            self.agent._log_and_report(f'Task stopped due to step limit: {max_steps}. You may need to start a new task to complete the remaining work.', actions_and_results, task_tag=task_tag)
        self.agent._conclude_task(f'(With device {self.device_name}) {task}', actions_and_results=actions_and_results)
        return results

    def _create_device_api_for_execution(self, notes, results, actions_and_results):
        """
        Create a DeviceAPI object that can be used in code execution.
        This object provides the device control APIs while preventing direct access to internal state.

        Args:
            notes: List to append text notes to
            results: List to append task results to
            actions_and_results: List to append actions and results (including images) to
        """
        class DeviceAPI:
            """Device control API for task execution."""
            def __init__(self, device_controller, notes, results, actions_and_results):
                self._device = device_controller
                self._notes = notes
                self._results = results
                self._actions_and_results = actions_and_results

            # Common device actions
            def click(self, x, y):
                """Click at coordinates (x, y)"""
                scaled_x, scaled_y = self._device._scale_coordinates_if_needed(x, y)
                return self._device.click(scaled_x, scaled_y)

            def view_set_text(self, content):
                """Type text content"""
                return self._device.view_set_text(content)

            def enter(self):
                """Press Enter key"""
                return self._device.enter()

            def scroll(self, direction, start_xy=None):
                """Scroll in direction ('up', 'down', 'left', 'right')"""
                if start_xy:
                    scaled_x, scaled_y = self._device._scale_coordinates_if_needed(start_xy[0], start_xy[1])
                    return self._device.scroll(direction, start_xy=(scaled_x, scaled_y))
                else:
                    return self._device.scroll(direction, start_xy=None)

            def drag(self, start_xy, end_xy):
                """Drag from start_xy to end_xy"""
                scaled_x1, scaled_y1 = self._device._scale_coordinates_if_needed(start_xy[0], start_xy[1])
                scaled_x2, scaled_y2 = self._device._scale_coordinates_if_needed(end_xy[0], end_xy[1])
                return self._device.drag((scaled_x1, scaled_y1), (scaled_x2, scaled_y2))

            def back(self):
                """Go back"""
                return self._device.back()

            def home(self):
                """Go to home"""
                return self._device.home()

            def start_app(self, app_name):
                """Start an application"""
                return self._device.start_app(app_name)

            # Computer-specific actions
            def double_click(self, x, y):
                """Double-click at coordinates (x, y)"""
                scaled_x, scaled_y = self._device._scale_coordinates_if_needed(x, y)
                return self._device.double_click(scaled_x, scaled_y)

            def right_click(self, x, y):
                """Right-click at coordinates (x, y)"""
                scaled_x, scaled_y = self._device._scale_coordinates_if_needed(x, y)
                return self._device.right_click(scaled_x, scaled_y)

            def hotkey(self, keys):
                """Press hotkey combination (e.g., 'ctrl c', 'cmd v')"""
                return self._device.hotkey(keys)

            # Phone/Browser-specific actions
            def long_click(self, x, y):
                """Long press at coordinates (x, y)"""
                scaled_x, scaled_y = self._device._scale_coordinates_if_needed(x, y)
                return self._device.long_click(scaled_x, scaled_y)

            def long_touch(self, x, y):
                """Long press at coordinates (x, y)"""
                scaled_x, scaled_y = self._device._scale_coordinates_if_needed(x, y)
                return self._device.long_touch(scaled_x, scaled_y)

            def open_url(self, url):
                """Open URL in browser"""
                return self._device.open_url(url)

            # Note-taking actions
            def take_note(self, text):
                """Record a text note"""
                self._notes.append(text)

            def take_note_screenshot(self, description, bbox=None):
                """
                Take and record a screenshot note with description.
                bbox is optional bounding box (x1, y1, x2, y2) to crop the screenshot.
                Coordinates in bbox will be scaled if needed.
                """
                import base64
                from io import BytesIO

                # Take screenshot
                screenshot = self._device.take_screenshot()

                # Crop if bbox is provided (scale coordinates first)
                if bbox is not None:
                    # bbox should be (x1, y1, x2, y2) - scale all coordinates
                    x1, y1, x2, y2 = bbox
                    scaled_x1, scaled_y1 = self._device._scale_coordinates_if_needed(x1, y1)
                    scaled_x2, scaled_y2 = self._device._scale_coordinates_if_needed(x2, y2)
                    screenshot = screenshot.crop((scaled_x1, scaled_y1, scaled_x2, scaled_y2))

                # Convert to base64
                img_byte_arr = BytesIO()
                screenshot.save(img_byte_arr, format='PNG')
                img_bytes = img_byte_arr.getvalue()
                screenshot_base64 = base64.b64encode(img_bytes).decode('utf-8')
                img_byte_arr.close()

                # Count existing screenshots to generate unique path
                # Count image tuples in actions_and_results
                screenshot_count = sum(1 for item in self._actions_and_results if isinstance(item, tuple) and len(item) == 2)
                screenshot_path = f"noted_image_{screenshot_count}.png"

                # Add to actions_and_results as an image tuple
                self._actions_and_results.append((screenshot_path, screenshot_base64))

                # Add text note with description
                self._notes.append(f"Screenshot: {description}")
                self._notes.append((screenshot_path, screenshot_base64))
                return screenshot

            # Result recording actions
            def record_result(self, content):
                """Record a task result (text)"""
                self._results.append(f"Result: {content}")

            def record_result_screenshot(self, description, bbox=None):
                """
                Take and record a screenshot of task result with description.
                bbox is optional bounding box (x1, y1, x2, y2) to crop the screenshot.
                Coordinates in bbox will be scaled if needed.
                """
                import base64
                from io import BytesIO

                # Take screenshot
                screenshot = self._device.take_screenshot()

                # Crop if bbox is provided (scale coordinates first)
                if bbox is not None:
                    # bbox should be (x1, y1, x2, y2) - scale all coordinates
                    x1, y1, x2, y2 = bbox
                    scaled_x1, scaled_y1 = self._device._scale_coordinates_if_needed(x1, y1)
                    scaled_x2, scaled_y2 = self._device._scale_coordinates_if_needed(x2, y2)
                    screenshot = screenshot.crop((scaled_x1, scaled_y1, scaled_x2, scaled_y2))

                # Convert to base64
                img_byte_arr = BytesIO()
                screenshot.save(img_byte_arr, format='PNG')
                img_bytes = img_byte_arr.getvalue()
                screenshot_base64 = base64.b64encode(img_bytes).decode('utf-8')
                img_byte_arr.close()

                # Count existing screenshots to generate unique path
                # Count image tuples in actions_and_results
                screenshot_count = sum(1 for item in self._actions_and_results if isinstance(item, tuple) and len(item) == 2)
                screenshot_path = f"result_image_{screenshot_count}.png"

                # Add to actions_and_results as an image tuple
                self._actions_and_results.append((screenshot_path, screenshot_base64))

                # Add text result with description
                self._results.append(f"Result Screenshot: {description}")
                self._results.append((screenshot_path, screenshot_base64))
                return screenshot

        return DeviceAPI(self, notes, results, actions_and_results)

    def _execute_device_action(self, action_str: str, device_type: str, notes: list):
        """
        Execute a device action parsed from LLM response.

        Args:
            action_str: Action string to execute
            device_type: Type of device ('computer', 'phone', 'browser')
            notes: List to append notes to
        """
        import re

        # Handle note-taking actions
        if action_str.startswith('take_note('):
            text_match = re.search(r"text='([^']*)'", action_str)
            if text_match:
                text = text_match.group(1)
                notes.append(text)
                logger.debug(f"ğŸ“ Note recorded: {text}")
                return

        elif action_str.startswith('take_note_screenshot('):
            # Take screenshot and add to notes
            screenshot = self.take_screenshot()
            notes.append(f"Screenshot captured at step")
            logger.debug(f"ğŸ“¸ Screenshot note recorded")
            return

        # Handle device control actions
        if action_str.startswith('click('):
            point_match = re.search(r"point='<point>(\d+)\s+(\d+)</point>'", action_str)
            if point_match:
                x, y = int(point_match.group(1)), int(point_match.group(2))
                # Scale coordinates if needed
                scaled_x, scaled_y = self._scale_coordinates_if_needed(x, y)
                self.click(scaled_x, scaled_y)
                logger.debug(f"ğŸ‘† Clicked at ({scaled_x}, {scaled_y})")

        elif action_str.startswith('type('):
            content_match = re.search(r"content='([^']*)'", action_str)
            if content_match:
                content = content_match.group(1)
                # Check if content ends with \n (submit)
                if content.endswith('\\n'):
                    actual_content = content[:-2]
                    self.view_set_text(actual_content)
                    time.sleep(0.1)
                    self.enter()
                    logger.debug(f"âŒ¨ï¸ Typed and submitted: {repr(actual_content)}")
                else:
                    self.view_set_text(content)
                    logger.debug(f"âŒ¨ï¸ Typed: {repr(content)}")

        elif action_str.startswith('scroll('):
            point_match = re.search(r"'<point>(\d+)\s+(\d+)</point>'", action_str)
            direction_match = re.search(r"direction='([^']+)'", action_str)
            if point_match and direction_match:
                x, y = int(point_match.group(1)), int(point_match.group(2))
                scaled_x, scaled_y = self._scale_coordinates_if_needed(x, y)
                direction = direction_match.group(1)
                self.scroll(direction, start_xy=(scaled_x, scaled_y))
                logger.debug(f"ğŸ“œ Scrolled {direction} at ({scaled_x}, {scaled_y})")

        elif action_str.startswith('drag('):
            start_match = re.search(r"start_point='<point>(\d+)\s+(\d+)</point>'", action_str)
            end_match = re.search(r"end_point='<point>(\d+)\s+(\d+)</point>'", action_str)
            if start_match and end_match:
                x1, y1 = int(start_match.group(1)), int(start_match.group(2))
                x2, y2 = int(end_match.group(1)), int(end_match.group(2))
                scaled_x1, scaled_y1 = self._scale_coordinates_if_needed(x1, y1)
                scaled_x2, scaled_y2 = self._scale_coordinates_if_needed(x2, y2)
                self._do_drag((scaled_x1, scaled_y1), (scaled_x2, scaled_y2))
                logger.debug(f"âœ‹ Dragged from ({scaled_x1}, {scaled_y1}) to ({scaled_x2}, {scaled_y2})")

        elif action_str.startswith('open_app(') or action_str.startswith('start_app('):
            app_match = re.search(r"app_name='([^']+)'", action_str)
            if app_match:
                app_name = app_match.group(1)
                self.start_app(app_name)
                logger.debug(f"ğŸ“± Started app: {app_name}")

        elif action_str.startswith('back('):
            self.back()
            logger.debug(f"â¬…ï¸ Pressed back")

        elif action_str.startswith('home('):
            self.home()
            logger.debug(f"ğŸ  Pressed home")

        elif action_str.startswith('enter('):
            self.enter()
            logger.debug(f"â†©ï¸ Pressed enter")

        # Computer-specific actions
        elif device_type == 'computer':
            if action_str.startswith('left_double(') or action_str.startswith('double_click('):
                point_match = re.search(r"point='<point>(\d+)\s+(\d+)</point>'", action_str)
                if point_match:
                    x, y = int(point_match.group(1)), int(point_match.group(2))
                    scaled_x, scaled_y = self._scale_coordinates_if_needed(x, y)
                    self.double_click(scaled_x, scaled_y)
                    logger.debug(f"ğŸ‘† Double-clicked at ({scaled_x}, {scaled_y})")

            elif action_str.startswith('right_single(') or action_str.startswith('right_click('):
                point_match = re.search(r"point='<point>(\d+)\s+(\d+)</point>'", action_str)
                if point_match:
                    x, y = int(point_match.group(1)), int(point_match.group(2))
                    scaled_x, scaled_y = self._scale_coordinates_if_needed(x, y)
                    self.right_click(scaled_x, scaled_y)
                    logger.debug(f"ğŸ–±ï¸ Right-clicked at ({scaled_x}, {scaled_y})")

            elif action_str.startswith('hotkey('):
                key_match = re.search(r"key='([^']+)'", action_str)
                if key_match:
                    keys = key_match.group(1)
                    self.hotkey(keys)
                    logger.debug(f"âŒ¨ï¸ Pressed hotkey: {keys}")

        # Phone/Browser-specific actions
        elif device_type in ['phone', 'browser']:
            if action_str.startswith('long_press(') or action_str.startswith('long_click('):
                point_match = re.search(r"point='<point>(\d+)\s+(\d+)</point>'", action_str)
                if point_match:
                    x, y = int(point_match.group(1)), int(point_match.group(2))
                    scaled_x, scaled_y = self._scale_coordinates_if_needed(x, y)
                    if device_type == 'browser':
                        self.long_touch(scaled_x, scaled_y)
                    else:
                        self.long_click(scaled_x, scaled_y)
                    logger.debug(f"ğŸ‘† Long-pressed at ({scaled_x}, {scaled_y})")

            elif action_str.startswith('open_url('):
                url_match = re.search(r"url='([^']+)'", action_str)
                if url_match:
                    url = url_match.group(1)
                    self.open_url(url)
                    logger.debug(f"ğŸŒ Opened URL: {url}")

    def get_width_height(self):
        """
        Get device width and height. Can be overridden by subclasses.
        Default implementation returns cached width/height.

        Returns:
            tuple: (width, height) in pixels
        """
        return (self.width, self.height)

    def _scale_coordinates_if_needed(self, x: int, y: int) -> tuple:
        """
        Scale coordinates from model output space (1000x1000) to actual device dimensions.

        Args:
            x: X coordinate from model (in 1000x1000 space)
            y: Y coordinate from model (in 1000x1000 space)

        Returns:
            tuple: (scaled_x, scaled_y) in actual device coordinates
        """
        # Model outputs coordinates in 1000x1000 space
        model_width = 1000
        model_height = 1000

        # Get actual device dimensions using get_width_height() method
        device_width, device_height = self.get_width_height()

        if device_width <= 0 or device_height <= 0:
            logger.error(f"Invalid device dimensions (width={device_width}, height={device_height}), using original coordinates")
            return (0, 0)

        # Calculate scaling ratios
        scale_x = device_width / model_width
        scale_y = device_height / model_height

        # Apply scaling
        scaled_x = int(x * scale_x)
        scaled_y = int(y * scale_y)

        # Ensure coordinates are within device bounds
        scaled_x = max(0, min(scaled_x, device_width - 1))
        scaled_y = max(0, min(scaled_y, device_height - 1))

        logger.debug(f"Coordinate scaling: ({x}, {y}) -> ({scaled_x}, {scaled_y}) (device: {device_width}x{device_height})")
        return (scaled_x, scaled_y)

    def _open(self):
        self._open_device()
        self.device_bound = (-1, -1, -1, -1)
        self.width = -1
        self.height = -1

    def _open_device(self):
        raise NotImplementedError("open_device not implemented")

    def _close(self):
        # Stop any active recording before closing device
        if self.recording_active:
            self.stop_recording()
        self._close_device()

    def _close_device(self):
        raise NotImplementedError("close_device not implemented")

    def take_picture(self, save_path=None):
        raise NotImplementedError("take_picture not implemented")

    def take_screenshot(self, save_path=None, hide_overlay = True):
        from mobileclaw.device.computer import ComputerDeviceBase

        def _take_screenshot():
            if isinstance(self, ComputerDeviceBase):
                image = self.take_screenshot_impl(save_path=save_path, hide_overlay=hide_overlay)
            else:
                image = self.take_screenshot_impl(save_path=save_path)
            return image

        image = _take_screenshot()

        for i in range(6):
            if self.check_black_screen(image):
                logger.info(f"Black screen detected on attempt {i+1}, retrying after 0.5s")
                self.agent.sleep(0.5)
                image = _take_screenshot()
            else:
                break

        if self.check_black_screen(image):
            logger.info(f"Black screen still detected after {i+1} attempts, requesting manual intervention")
            self._notify_black_screen()
            return _take_screenshot()
        else:
            self.width, self.height = image.size
            return image

    def take_screenshot_impl(self, save_path=None):
        raise NotImplementedError("take_screenshot_impl not implemented")

    def check_black_screen(self, image: Image.Image) -> bool:
        """æ£€æµ‹æˆªå›¾æ˜¯å¦ä¸ºé»‘å±ï¼Œå¦‚æœæ˜¯åˆ™é€šçŸ¥ç”¨æˆ·
        
        é»‘å±åˆ¤å®šæ ‡å‡†ï¼šçº¯é»‘åƒç´ ï¼ˆRGBå…¨ä¸º0ï¼‰å æ¯”è¾¾åˆ°90%ä»¥ä¸Š
        
        Args:
            image: PIL Image å¯¹è±¡
            
        Returns:
            bool: å¦‚æœæ˜¯é»‘å±è¿”å› Trueï¼Œå¦åˆ™è¿”å› False
        """
        try:
            # è½¬æ¢ä¸ºRGBæ¨¡å¼
            if image.mode == 'RGBA':
                img = image.convert('RGB')
            elif image.mode != 'RGB':
                img = image.convert('RGB')
            else:
                img = image
            
            # è½¬æ¢ä¸ºnumpyæ•°ç»„
            pixels = np.array(img)
            
            # è·å–å›¾ç‰‡å°ºå¯¸
            height, width = pixels.shape[:2]
            total_pixels = height * width
            
            if total_pixels == 0:
                return False
            
            # è®¡ç®—çº¯é»‘åƒç´ ï¼ˆRGBå…¨ä¸º0ï¼‰
            black_mask = (pixels[:, :, 0] == 0) & (pixels[:, :, 1] == 0) & (pixels[:, :, 2] == 0)
            black_pixels = np.sum(black_mask)
            black_ratio = black_pixels / total_pixels

            # å¦‚æœé»‘è‰²åƒç´ å æ¯”è¶…è¿‡95%ï¼Œè§†ä¸ºé»‘å±
            if black_ratio >= 0.95:
                return True
            
            return False
        except Exception as e:
            logger.debug(f"æ£€æµ‹é»‘å±å¤±è´¥: {str(e)}")
            return False

    def _notify_black_screen(self):
        """é€šçŸ¥ç”¨æˆ·æˆªå›¾ä¸ºé»‘å±ï¼Œå¹¶è¯·æ±‚æ‰‹åŠ¨æ¥ç®¡"""
        try:
            # æ ¹æ®ä»»åŠ¡è¯­è¨€é€‰æ‹©æ¶ˆæ¯
            task_language = getattr(self.agent, 'task_language', 'zh')
            if task_language == 'en':
                message = f'The screen captured from device "{self.device_name}" is black. The device may be in a privacy protection screen, and the task execution may encounter errors. Please manually handle it and click "Takeover Ended" when done.'
            else:
                message = f'æ£€æµ‹åˆ°è®¾å¤‡ "{self.device_name}" çš„å±å¹•æˆªå›¾æ˜¯é»‘å±ï¼Œå½“å‰è¯¥è®¾å¤‡å¯èƒ½å¤„äºéšç§ä¿æŠ¤ç•Œé¢ï¼Œä»»åŠ¡æ‰§è¡Œè¿‡ç¨‹å¯èƒ½ä¼šå‡ºé”™ï¼Œè¯·æ‚¨æ‰‹åŠ¨è¿›è¡Œå¤„ç†ï¼Œå¤„ç†å®Œæˆåç‚¹å‡»"æ¥ç®¡ç»“æŸ"æŒ‰é’®ã€‚'
            
            # è¯·æ±‚æ‰‹åŠ¨æ¥ç®¡ï¼ˆä¼šç­‰å¾…ç”¨æˆ·ç¡®è®¤æˆ–è¶…æ—¶ï¼‰
            logger.info(f"âš ï¸ {message}")
            # self.agent.user.request_manual_takeover(message, timeout=30)
        except Exception as e:
            logger.debug(f"è¯·æ±‚æ‰‹åŠ¨æ¥ç®¡å¤±è´¥: {str(e)}")

    def start_app(self, app_name):
        # Record action for video if recording
        self.record_action_if_recording(
            "start_app",
            app_name=app_name
        )
        # Subclasses should override and call _notify_app_started after successful start
        raise NotImplementedError("start_app not implemented")
    
    def _get_app_info(self, app_name: str, **kwargs) -> dict:
        """è·å–åº”ç”¨ä¿¡æ¯ï¼ˆç”±å­ç±»å®ç°ï¼‰
        
        Args:
            app_name: åº”ç”¨åç§°
            **kwargs: å…¶ä»–å¯é€‰å‚æ•°ï¼ˆå¦‚ bundle_id ç­‰ï¼‰
            
        Returns:
            dict: åº”ç”¨ä¿¡æ¯å­—å…¸ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
                - bundle_id: åº”ç”¨çš„å”¯ä¸€æ ‡è¯†
                - name: åº”ç”¨åç§°
                - type: åº”ç”¨ç±»å‹ (1: ç”µè„‘ç«¯, 3: Androidç«¯)
                - version: åº”ç”¨ç‰ˆæœ¬
                - display_name: æ˜¾ç¤ºåç§°ï¼ˆå¯é€‰ï¼‰
                - developer: å¼€å‘è€…ï¼ˆå¯é€‰ï¼‰
                - description: æè¿°ï¼ˆå¯é€‰ï¼‰
                - category: ç±»åˆ«ï¼ˆå¯é€‰ï¼‰
                - icon: å›¾æ ‡ï¼ˆå¯é€‰ï¼‰
        """
        raise NotImplementedError("_get_app_info not implemented")
    
    def _notify_app_started(self, app_name: str, **kwargs):
        """åº”ç”¨å¯åŠ¨æˆåŠŸåï¼Œè·å–åº”ç”¨ä¿¡æ¯å¹¶å‘é€åˆ°Flaskåç«¯
        
        Args:
            app_name: å¯åŠ¨çš„åº”ç”¨åç§°
            **kwargs: å…¶ä»–å¯é€‰å‚æ•°ï¼ˆå¦‚ bundle_id ç­‰ï¼‰ï¼Œä¼ é€’ç»™ _get_app_info
        """
        if not self.agent.config.run_with_ide:
            return
        
        try:
            # è·å–åº”ç”¨ä¿¡æ¯
            app_info = self._get_app_info(app_name, **kwargs)
            
            # å‘é€åˆ° Flask åç«¯
            self._send_app_info_to_flask(app_info)
            
        except Exception as e:
            logger.debug(f"å‘é€åº”ç”¨ä¿¡æ¯å¤±è´¥: {str(e)}")
    
    def _send_app_info_to_flask(self, app_info: dict):
        """å°†åº”ç”¨ä¿¡æ¯å‘é€åˆ°Flaskåç«¯
        
        Args:
            app_info: åº”ç”¨ä¿¡æ¯å­—å…¸
        """
        try:
            flask_port = self.config.flask_port
            response = requests.post(
                f'http://localhost:{flask_port}/app_started',
                json={'app_info': app_info, 'task_id': getattr(self.agent.task, 'task_id', '')},
                headers={'Content-Type': 'application/json'},
                timeout=2
            )
            
            if response.status_code == 200:
                logger.debug(f"åº”ç”¨ä¿¡æ¯å·²å‘é€åˆ°Flaskåç«¯: {app_info.get('name', 'unknown')}")
            else:
                logger.debug(f"å‘é€åº”ç”¨ä¿¡æ¯å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                
        except Exception as e:
            logger.debug(f"å‘é€åº”ç”¨ä¿¡æ¯åˆ°Flaskå¤±è´¥: {str(e)}")

    def stop_app(self, app_name):
        raise NotImplementedError("stop_app not implemented")

    def push_file(self, local_file_path, remote_file_path):
        raise NotImplementedError("push_file not implemented")

    def pull_file(self, remote_file_path, local_file_path):
        raise NotImplementedError("pull_file not implemented")

    def key_press(self, key):
        # Record action for video if recording
        self.record_action_if_recording(
            "key_press",
            key=key
        )
        raise NotImplementedError("key_press not implemented")

    def back(self):
        # Record action for video if recording
        self.record_action_if_recording("back")
        raise NotImplementedError("back not implemented")

    def home(self):
        # Record action for video if recording
        self.record_action_if_recording("home")
        raise NotImplementedError("home not implemented")

    def long_touch(self, x, y, duration=None):
        # Record action for video if recording
        self.record_action_if_recording(
            "long_touch",
            coordinates=(x, y),
            duration=duration
        )
        raise NotImplementedError("long_touch not implemented")

    def drag(self, start_xy, end_xy, duration=None):
        # check if the drag is within the device bound
        start_xy, end_xy = self._check_drag_bound(start_xy, end_xy)
        self._do_drag(start_xy, end_xy, duration)

    def _check_drag_bound(self, start_xy, end_xy):
        # è·å–è®¾å¤‡è¾¹ç•Œ
        x_min, y_min, x_max, y_max = self.device_bound

        def is_inside(xy):
            x, y = xy
            return x_min <= x <= x_max and y_min <= y <= y_max

        def line_intersection(p1, p2, q1, q2):
            # è®¡ç®—ä¸¤æ¡çº¿æ®µçš„äº¤ç‚¹
            def det(a, b, c, d):
                return a * d - b * c

            x1, y1 = p1
            x2, y2 = p2
            x3, y3 = q1
            x4, y4 = q2

            denom = det(x1 - x2, y1 - y2, x3 - x4, y3 - y4)
            if denom == 0:
                return None  # å¹³è¡Œæˆ–é‡åˆ

            det1 = det(x1, y1, x2, y2)
            det2 = det(x3, y3, x4, y4)
            x = det(det1, x1 - x2, det2, x3 - x4) / denom
            y = det(det1, y1 - y2, det2, y3 - y4) / denom

            if (min(x1, x2) <= x <= max(x1, x2) and min(y1, y2) <= y <= max(y1, y2) and
                    min(x3, x4) <= x <= max(x3, x4) and min(y3, y4) <= y <= max(y3, y4)):
                return (x, y)
            return None

        # çŸ©å½¢çš„å››æ¡è¾¹
        edges = [
            ((x_min, y_min), (x_max, y_min)),  # ä¸Šè¾¹
            ((x_max, y_min), (x_max, y_max)),  # å³è¾¹
            ((x_max, y_max), (x_min, y_max)),  # ä¸‹è¾¹
            ((x_min, y_max), (x_min, y_min))   # å·¦è¾¹
        ]

        if is_inside(start_xy) and is_inside(end_xy):
            return start_xy, end_xy

        intersections = []
        for edge in edges:
            intersection = line_intersection(start_xy, end_xy, *edge)
            if intersection:
                intersections.append(intersection)

        if len(intersections) == 2:
            return intersections[0], intersections[1]
        elif len(intersections) == 1:
            if is_inside(start_xy):
                return start_xy, intersections[0]
            elif is_inside(end_xy):
                return intersections[0], end_xy
        else:
            return start_xy, end_xy

    def _do_drag(self, start_xy, end_xy, duration=None):
        # Record action for video if recording
        self.record_action_if_recording(
            "drag",
            start_xy=start_xy,
            end_xy=end_xy,
            duration=duration
        )
        raise NotImplementedError("_do_drag not implemented")

    def get_current_state(self):
        raise NotImplementedError("get_current_state not implemented")

    def view_set_text(self, text):
        raise NotImplementedError("view_set_text not implemented")

    def view_append_text(self, text):
        raise NotImplementedError("view_append_text not implemented")

    def start_screen_record(self):
        raise NotImplementedError("start_screen_record not implemented")

    def stop_screen_record(self):
        raise NotImplementedError("stop_screen_record not implemented")

    def show_highlight(self, x, y, radius):
        raise NotImplementedError("show_highlight not implemented")

    def hide_highlight(self):
        raise NotImplementedError("hide_highlight not implemented")

    def get_clipboard(self) -> str:
        raise NotImplementedError("get_clipboard not implemented")

    def set_clipboard(self, text: str) -> bool:
        raise NotImplementedError("set_clipboard not implemented")

    def expand_notification_panel(self):
        raise NotImplementedError("expand_notification_panel not implemented")

    def _find_device_with_bilingual_match(self, input_device_name: str, device_mappings: dict) -> str:
        """åŒè¯­åŒ¹é…è®¾å¤‡åç§°
        
        æ”¯æŒä¸­è‹±æ–‡è®¾å¤‡åç§°çš„åŒå‘åŒ¹é…ï¼ŒåŒ…æ‹¬ï¼š
        - æµè§ˆå™¨ <-> browser
        - æ‰‹æœº <-> phone  
        - äº‘æ‰‹æœº <-> cloud phone
        
        Args:
            input_device_name: ç”¨æˆ·è¾“å…¥çš„è®¾å¤‡åç§°
            device_mappings: é…ç½®æ–‡ä»¶ä¸­çš„è®¾å¤‡æ˜ å°„
            
        Returns:
            str: åŒ¹é…åˆ°çš„è®¾å¤‡åç§°ï¼Œå¦‚æœæ²¡æœ‰åŒ¹é…è¿”å›None
        """
        # è®¾å¤‡ç±»å‹çš„ä¸­è‹±æ–‡æ˜ å°„
        device_type_mappings = {
            # ä¸­æ–‡åˆ°è‹±æ–‡
            'æµè§ˆå™¨': 'browser',
            'æ‰‹æœº': 'phone',
            'äº‘æ‰‹æœº': 'cloud phone',
            'ç”µè„‘': 'computer',
            # è‹±æ–‡åˆ°ä¸­æ–‡  
            'browser': 'æµè§ˆå™¨',
            'phone': 'æ‰‹æœº',
            'cloud phone': 'äº‘æ‰‹æœº',
            'cloudphone': 'äº‘æ‰‹æœº',  # æ”¯æŒè¿å†™
            'cloud_phone': 'äº‘æ‰‹æœº',  # æ”¯æŒä¸‹åˆ’çº¿
            'computer': 'ç”µè„‘',
            'pc': 'ç”µè„‘',
            'desktop': 'ç”µè„‘',
        }
        
        import re
        
        # æ ‡å‡†åŒ–è¾“å…¥åç§°ï¼ˆè½¬ä¸ºå°å†™ï¼Œç»Ÿä¸€åˆ†éš”ç¬¦ï¼‰
        normalized_input = input_device_name.lower().replace('_', ' ').replace('-', ' ')
        
        # å°è¯•ç›´æ¥åŒ¹é…
        if input_device_name in device_mappings:
            return input_device_name
            
        # æå–è®¾å¤‡ç±»å‹å’Œæ•°å­—åç¼€
        def parse_device_name(name):
            """è§£æè®¾å¤‡åç§°ï¼Œè¿”å›(è®¾å¤‡ç±»å‹, æ•°å­—åç¼€)"""
            name = name.lower().strip()
            # åŒ¹é…æœ«å°¾çš„æ•°å­—
            match = re.match(r'^(.+?)(\d*)$', name)
            if match:
                device_type = match.group(1).strip()
                number = match.group(2) if match.group(2) else ''
                return device_type, number
            return name, ''
        
        input_type, input_number = parse_device_name(normalized_input)

        # å½“è¾“å…¥æ²¡æœ‰æ•°å­—åç¼€æ—¶ï¼Œé»˜è®¤å€™é€‰æ•°å­—ä¸º ['1', '']ï¼Œä¼˜å…ˆåŒ¹é… 1ï¼ŒåŒæ—¶å…¼å®¹æ²¡æœ‰æ•°å­—çš„é…ç½®é”®
        candidate_numbers = ['1', ''] if input_number == '' else [input_number]
        
        # éå†å€™é€‰æ•°å­—ä¸é…ç½®ä¸­çš„æ‰€æœ‰è®¾å¤‡åç§°è¿›è¡ŒåŒ¹é…ï¼Œä¼˜å…ˆåŒ¹é… '1'
        for candidate_number in candidate_numbers:
            for config_device_name in device_mappings.keys():
                config_type, config_number = parse_device_name(config_device_name)
                
                # å¦‚æœæ•°å­—åç¼€ä¸åŒ¹é…ï¼Œè·³è¿‡
                if config_number != candidate_number:
                    continue
                    
                # æ£€æŸ¥è®¾å¤‡ç±»å‹æ˜¯å¦åŒ¹é…
                # 1. ç›´æ¥åŒ¹é…
                if input_type == config_type:
                    return config_device_name
                    
                # 2. é€šè¿‡æ˜ å°„è¡¨åŒ¹é…
                if input_type in device_type_mappings:
                    mapped_type = device_type_mappings[input_type]
                    if mapped_type == config_type:
                        return config_device_name
                        
                # 3. åå‘æ˜ å°„åŒ¹é…
                if config_type in device_type_mappings:
                    mapped_config_type = device_type_mappings[config_type]
                    if input_type == mapped_config_type:
                        return config_device_name
        
        return None

    def set_device(self, device_name: str) -> bool:
        """å…¬å…±æ–¹æ³•ï¼Œä¼šåœ¨æ‰€æœ‰è®¾å¤‡ç±»å‹ä¸­æŸ¥æ‰¾æŒ‡å®šçš„è®¾å¤‡åç§°ï¼Œ
        å¹¶è°ƒç”¨å­ç±»å®ç°çš„ _do_device_switch æ–¹æ³•æ¥æ‰§è¡Œå®é™…çš„è®¾å¤‡åˆ‡æ¢ã€‚
        æ”¯æŒä¸­è‹±æ–‡è®¾å¤‡åç§°çš„åŒå‘åŒ¹é…ã€‚
        
        Args:
            device_name: è®¾å¤‡åç§°ï¼Œæ”¯æŒä¸­è‹±æ–‡ï¼Œå¦‚"æµè§ˆå™¨1"ã€"browser1"ç­‰
            
        Returns:
            bool: åˆ‡æ¢æ˜¯å¦æˆåŠŸ
            
        Raises:
            ValueError: å½“è®¾å¤‡åç§°ä¸å­˜åœ¨äºdevice_mappingsä¸­æ—¶
            DeviceTypeMismatchError: å½“è®¾å¤‡ç±»å‹ä¸åŒ¹é…æ—¶ï¼ˆæœªæ¥æ‰©å±•ï¼‰
        """
        try:
            # 1. æ£€æŸ¥è®¾å¤‡æ˜¯å¦å­˜åœ¨äºæ˜ å°„è¡¨ä¸­
            if not hasattr(self.config, 'device_mappings') or not self.config.device_mappings:
                raise ValueError("No device mappings configured")
            
            # 2. å°è¯•åŒè¯­åŒ¹é…æŸ¥æ‰¾è®¾å¤‡
            matched_device_name = self._find_device_with_bilingual_match(device_name, self.config.device_mappings)
            
            if matched_device_name is None:
                # æä¾›æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯ï¼Œåˆ—å‡ºæ‰€æœ‰å¯ç”¨è®¾å¤‡
                available_devices = list(self.config.device_mappings.keys())
                raise ValueError(
                    f"Device '{device_name}' not found in device mappings. "
                    f"Available devices: {available_devices}. "
                    f"Supports bilingual matching: æµè§ˆå™¨/browser, æ‰‹æœº/phone, äº‘æ‰‹æœº/cloud phone, ç”µè„‘/computer"
                )
            
            # 3. è·å–ç›®æ ‡è®¾å¤‡ID
            target_device_id = self.config.device_mappings[matched_device_name]
            
            # 4. è°ƒç”¨å­ç±»å®ç°çš„è®¾å¤‡åˆ‡æ¢æ–¹æ³•
            success = self._do_device_switch(matched_device_name, target_device_id)
            
            if success:
                # æ ¹æ®è®¾å¤‡åç§°é€‰æ‹©æ›´åˆé€‚çš„ emojiï¼ˆbrowser/æµè§ˆå™¨ -> ğŸŒï¼Œphone/æ‰‹æœº -> ğŸ“±ï¼Œcomputer/ç”µè„‘/pc/desktop -> ğŸ–¥ï¸ï¼‰
                _name_lower = str(matched_device_name).lower()
                _emoji = "ğŸ–¥ï¸"
                if ("browser" in _name_lower) or ("æµè§ˆå™¨" in matched_device_name):
                    _emoji = "ğŸŒ"
                elif ("phone" in _name_lower) or ("æ‰‹æœº" in matched_device_name):
                    _emoji = "ğŸ“±"
                elif ("computer" in _name_lower) or ("ç”µè„‘" in matched_device_name) or ("pc" in _name_lower) or ("desktop" in _name_lower):
                    _emoji = "ğŸ–¥ï¸"
                logger.info(f"{_emoji} è®¾ç½®å½“å‰æ‰§è¡Œè®¾å¤‡ä¸ºï¼š\"{matched_device_name}\"")
                if device_name != matched_device_name:
                    pass
                    # logger.debug(f"Device name '{device_name}' matched to '{matched_device_name}'")

                # è®°å½•è½¨è¿¹ï¼šè®¾ç½®è®¾å¤‡
                try:
                    self.agent.sleep(1)
                    #     action_type="set_device",
                    #     action_params={
                    #         "device": matched_device_name
                    #     }
                    # )
                except Exception as _e:
                    logger.debug(f"è®°å½•è®¾å¤‡åˆ‡æ¢è½¨è¿¹å¤±è´¥: {_e}")
            else:
                logger.error(f"âŒ è®¾ç½®æ‰§è¡Œè®¾å¤‡ä¸ºï¼š\"{matched_device_name}\" å¤±è´¥")
                # logger.debug(f"Failed to switch to device: {matched_device_name}")
                
            return success
            
        except Exception as e:
            logger.error(f"âŒ è®¾ç½®æ‰§è¡Œè®¾å¤‡ä¸ºï¼š\"{device_name}\" å¤±è´¥: {str(e)}")
            return False

    def _do_device_switch(self, device_name: str, device_id: str) -> bool:
        """æ‰§è¡Œå…·ä½“çš„è®¾å¤‡åˆ‡æ¢æ“ä½œ
        
        è¿™æ˜¯ä¸€ä¸ªæŠ½è±¡æ–¹æ³•ï¼Œéœ€è¦ç”±å­ç±»å®ç°å…·ä½“çš„è®¾å¤‡åˆ‡æ¢é€»è¾‘ã€‚
        æ¯ç§è®¾å¤‡ç±»å‹éƒ½æœ‰ä¸åŒçš„åˆ‡æ¢æ–¹å¼ï¼š
        - WebSocketè®¾å¤‡éœ€è¦å…³é—­è¿æ¥ã€è®¾ç½®ç«¯å£è½¬å‘ã€é‡æ–°è¿æ¥
        - Browserè®¾å¤‡éœ€è¦åˆ‡æ¢BrowserView
        
        Args:
            device_name: è®¾å¤‡åç§°
            device_id: è®¾å¤‡IDï¼ˆä»device_mappingsä¸­è·å–ï¼‰
            
        Returns:
            bool: åˆ‡æ¢æ˜¯å¦æˆåŠŸ
        """
        raise NotImplementedError("_do_device_switch not implemented by subclass")

    def take_screenshot_by_description(self, description: str, save_path: Optional[str] = None) -> Image.Image:
        """æ ¹æ®æè¿°å®šä½å…ƒç´ å¹¶æˆªå–è¯¥åŒºåŸŸçš„æˆªå›¾

        Args:
            description: è¦å®šä½çš„å…ƒç´ çš„è‡ªç„¶è¯­è¨€æè¿°ï¼Œä¾‹å¦‚ "æœç´¢æŒ‰é’®" æˆ– "é¡µé¢é¡¶éƒ¨çš„å¯¼èˆªæ "
            save_path: å¯é€‰çš„ä¿å­˜è·¯å¾„

        Returns:
            PIL.Image.Image: è£å‰ªåçš„å›¾åƒå¯¹è±¡

        Raises:
            RuntimeError: å½“æ— æ³•å®šä½åˆ°æè¿°çš„å…ƒç´ æ—¶
            ValueError: å½“æè¿°ä¸ºç©ºæ—¶
        """
        if not description:
            raise ValueError("Description cannot be empty")

        try:
            # é¦–å…ˆè·å–å®Œæ•´æˆªå›¾
            full_screenshot = self.take_screenshot()

            # ä½¿ç”¨UIæ¥å£å®šä½å…ƒç´ 
            raise NotImplementedError("locate_view requires ui module which has been removed")

            # è·å–å…ƒç´ çš„è¾¹ç•Œæ¡†
            bound = located_view._get_bound()

            if bound is None or bound == (None, None, None, None):
                raise RuntimeError(f"Failed to locate element with description: '{description}'")

            x0, y0, x1, y1 = bound

            # ç¡®ä¿åæ ‡æœ‰æ•ˆ
            if x0 is None or y0 is None or x1 is None or y1 is None:
                raise RuntimeError(f"Invalid bounding box for element: '{description}'")

            # ç¡®ä¿è¾¹ç•Œæ¡†åœ¨å›¾åƒèŒƒå›´å†…
            img_width, img_height = full_screenshot.size
            x0 = max(0, min(int(x0), img_width))
            y0 = max(0, min(int(y0), img_height))
            x1 = max(0, min(int(x1), img_width))
            y1 = max(0, min(int(y1), img_height))

            # ç¡®ä¿x1 > x0 å’Œ y1 > y0
            if x1 <= x0 or y1 <= y0:
                # å¦‚æœè¾¹ç•Œæ¡†æ˜¯ç‚¹åæ ‡ï¼Œæ‰©å±•ä¸ºå°åŒºåŸŸ
                center_x, center_y = (x0 + x1) // 2, (y0 + y1) // 2
                padding = 50  # 50åƒç´ çš„è¾¹è·
                x0 = max(0, center_x - padding)
                y0 = max(0, center_y - padding)
                x1 = min(img_width, center_x + padding)
                y1 = min(img_height, center_y + padding)

            # è£å‰ªå›¾åƒ
            cropped_image = full_screenshot.crop((x0, y0, x1, y1))

            # ä¿å­˜å›¾åƒï¼ˆå¦‚æœæŒ‡å®šäº†è·¯å¾„ï¼‰
            if save_path:
                cropped_image.save(save_path)

            logger.info(f"ğŸ“¸ æˆåŠŸæˆªå–äº†â€œ{description}â€çš„å›¾ç‰‡")
            logger.debug(f"æˆåŠŸæˆªå–äº†â€œ{description}â€çš„æˆªå›¾ï¼Œæˆªå–èŒƒå›´ä¸ºï¼š({x0}, {y0}, {x1}, {y1})")
            # å…³é—­åŸå§‹æˆªå›¾ä»¥é‡Šæ”¾å†…å­˜
            full_screenshot.close()

            return cropped_image

        except Exception as e:
            logger.info(f"âš ï¸ æˆªå–â€œ{description}â€çš„å›¾ç‰‡å¤±è´¥: {str(e)}")
            raise RuntimeError(f"æˆªå–â€œ{description}â€çš„å›¾ç‰‡å¤±è´¥: {str(e)}")

    def start_recording(self, output_path=None):
        """å¼€å§‹è§†é¢‘å½•åˆ¶
        
        Args:
            output_path (str, optional): è¾“å‡ºè§†é¢‘æ–‡ä»¶è·¯å¾„ã€‚å¦‚æœæœªæŒ‡å®šï¼Œå°†è‡ªåŠ¨ç”Ÿæˆã€‚
            
        Returns:
            str: å½•åˆ¶æ–‡ä»¶è·¯å¾„
            
        Raises:
            RuntimeError: å½“å·²ç»åœ¨å½•åˆ¶æ—¶
            ImportError: å½“è§†é¢‘ç¼–ç æœåŠ¡ä¸å¯ç”¨æ—¶
        """
        if self.recording_active:
            raise RuntimeError("å½•åˆ¶å·²ç»åœ¨è¿›è¡Œä¸­")
            
        try:
            # Import video encoder service
            from mobileclaw.services.video_encoder import VideoEncoderService
            self.recording_encoder = VideoEncoderService()
        except ImportError:
            raise ImportError("è§†é¢‘ç¼–ç æœåŠ¡ä¸å¯ç”¨ï¼Œè¯·ç¡®ä¿å·²å®‰è£…å¿…è¦çš„ä¾èµ–")
        
        # Generate output path if not provided
        if output_path is None:
            timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
            task_name = getattr(self.agent, "current_task_name", "task")
            output_path = os.path.join(
                getattr(self.agent, "workspace_path", os.getcwd()),
                "recordings",
                f"{timestamp}_{task_name}_recording_{self.device_name}.mp4"
            )
            
        # Ensure recordings directory exists
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        
        # Reset recording state
        self.recording_output_path = output_path
        self.recording_stop_requested = False
        self.recording_frames = []
        self.recording_start_time = time.time()
        self.recording_stop_time = None
        
        # Initialize recording metadata
        task_name = getattr(self.agent, 'current_task_name', 'task')
        self.recording_metadata = {
            'task_name': task_name,
            'device_id': self.device_id,
            'device_name': self.device_name,
            'device_type': getattr(self, '__class__.__name__', 'unknown'),
            'start_time': self.recording_start_time,
            'start_time_iso': datetime.fromtimestamp(self.recording_start_time).isoformat(),
            'stop_time': None,
            'stop_time_iso': None,
            'duration_seconds': None,
            'file_size_bytes': None,
            'frame_count': 0,
            'output_path': output_path,
            'gui_actions': [],  # Will be populated during recording
            'action_timeline_summary': {}  # Will be calculated after recording
        }
        
        # Clear frame queue
        while not self.recording_frame_queue.empty():
            try:
                self.recording_frame_queue.get_nowait()
            except queue.Empty:
                break
        
        # Start recording thread
        self.recording_active = True
        self.recording_thread = threading.Thread(target=self._recording_worker, daemon=True)
        self.recording_thread.start()
        
        logger.info(f"ğŸ¬ å¼€å§‹è§†é¢‘å½•åˆ¶: {output_path}")
        return output_path

    def stop_recording(self):
        """åœæ­¢è§†é¢‘å½•åˆ¶
        
        Returns:
            str: å½•åˆ¶è§†é¢‘æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœå½•åˆ¶å¤±è´¥è¿”å›None
        """
        if not self.recording_active:
            logger.warning("æ²¡æœ‰è¿›è¡Œä¸­çš„å½•åˆ¶å¯ä»¥åœæ­¢")
            return None
            
        logger.info("â¹ï¸ åœæ­¢è§†é¢‘å½•åˆ¶...")
        
        # Capture stop time
        self.recording_stop_time = time.time()
        
        # Update metadata with stop information
        if self.recording_metadata:
            self.recording_metadata.update({
                'stop_time': self.recording_stop_time,
                'stop_time_iso': datetime.fromtimestamp(self.recording_stop_time).isoformat(),
                'frame_count': len(self.recording_frames),
                'gui_actions': self.recording_action_timeline,
            })
            if self.recording_start_time:
                duration = self.recording_stop_time - self.recording_start_time
                self.recording_metadata['duration_seconds'] = duration
            
            # Calculate action timeline summary
            if self.recording_action_timeline:
                action_types = [action['action_type'] for action in self.recording_action_timeline]
                action_counts = {}
                for action_type in action_types:
                    action_counts[action_type] = action_types.count(action_type)
                
                self.recording_metadata['action_timeline_summary'] = {
                    'total_actions': len(self.recording_action_timeline),
                    'actions_per_second': len(self.recording_action_timeline) / duration if duration > 0 else 0,
                    'most_common_action': max(action_counts, key=action_counts.get) if action_counts else None,
                    'action_distribution': action_counts,
                    'first_action_time': self.recording_action_timeline[0]['timestamp_iso'] if self.recording_action_timeline else None,
                    'last_action_time': self.recording_action_timeline[-1]['timestamp_iso'] if self.recording_action_timeline else None
                }
        
        # Signal stop
        self.recording_stop_requested = True
        self.recording_active = False
        
        # Wait for recording thread to finish
        if self.recording_thread and self.recording_thread.is_alive():
            self.recording_thread.join(timeout=5.0)
        
        # Process recorded frames into video
        video_path = None
        if self.recording_frames:
            try:
                video_path = self.recording_encoder.encode_frames_to_video(
                    self.recording_frames,
                    self.recording_output_path,
                    self.recording_metadata  # Pass metadata to encoder
                )
                
                # Update metadata with file information
                if video_path and os.path.exists(video_path):
                    file_size = os.path.getsize(video_path)
                    self.recording_metadata['file_size_bytes'] = file_size
                    
                    # Save metadata to a JSON file alongside the video
                    metadata_path = video_path.replace('.mp4', '_metadata.json')
                    import json
                    with open(metadata_path, 'w', encoding='utf-8') as f:
                        json.dump(self.recording_metadata, f, indent=2, ensure_ascii=False)
                    
                    duration = self.recording_stop_time - self.recording_start_time if self.recording_start_time else 0
                    logger.info(f"âœ… è§†é¢‘å½•åˆ¶å®Œæˆ: {video_path} (æ—¶é•¿: {duration:.1f}s, å¸§æ•°: {len(self.recording_frames)}, å¤§å°: {file_size:,} bytes)")
            except Exception as e:
                logger.error(f"âŒ è§†é¢‘ç¼–ç å¤±è´¥: {str(e)}")
        else:
            logger.warning("æ²¡æœ‰å½•åˆ¶åˆ°ä»»ä½•å¸§")
        
        # Cleanup state
        self.recording_frames = []
        self.recording_stop_requested = False
        self.recording_start_time = None
        self.recording_stop_time = None
        self.recording_thread = None
        
        return video_path

    def is_recording(self):
        """æ£€æŸ¥æ˜¯å¦æ­£åœ¨å½•åˆ¶
        
        Returns:
            bool: å¦‚æœæ­£åœ¨å½•åˆ¶è¿”å›Trueï¼Œå¦åˆ™è¿”å›False
        """
        return self.recording_active

    def _recording_worker(self):
        """å½•åˆ¶å·¥ä½œçº¿ç¨‹ï¼ŒæŒç»­æ•è·å±å¹•å¸§"""
        import structlog
        logger = structlog.get_logger(__name__)
        
        frame_count = 0
        last_frame_time = time.time()
        
        # Determine appropriate frame interval based on device capabilities
        frame_interval = self._get_optimal_frame_interval()
        
        try:
            while not self.recording_stop_requested:
                try:
                    current_time = time.time()
                    
                    # Limit frame rate to prevent performance issues
                    if current_time - last_frame_time < frame_interval:
                        time.sleep(0.001)  # Small sleep to prevent CPU spinning
                        continue
                    
                    # Capture frame
                    frame = self.take_screenshot()
                    if frame is not None:
                        # Add timestamp to frame
                        frame_data = {
                            "image": frame,
                            "timestamp": current_time,
                            "frame_number": frame_count
                        }
                        
                        # Use queue for thread-safe frame buffering
                        try:
                            self.recording_frame_queue.put_nowait(frame_data)
                        except queue.Full:
                            # If queue is full, remove oldest frame and add new one
                            try:
                                self.recording_frame_queue.get_nowait()
                                self.recording_frame_queue.put_nowait(frame_data)
                            except queue.Empty:
                                pass
                        
                        # Store frames for encoding (limit to prevent memory issues)
                        if len(self.recording_frames) < 3600:  # Max 1 hour at 1fps
                            self.recording_frames.append(frame_data)
                        
                        frame_count += 1
                        last_frame_time = current_time
                    
                except Exception as e:
                    logger.debug(f"å½•åˆ¶å¸§æ•è·å¤±è´¥: {str(e)}")
                    time.sleep(0.1)  # Brief pause on error
                    
        except Exception as e:
            logger.error(f"å½•åˆ¶å·¥ä½œçº¿ç¨‹å¼‚å¸¸: {str(e)}")
            
        logger.debug(f"å½•åˆ¶çº¿ç¨‹ç»“æŸï¼Œå…±æ•è· {frame_count} å¸§")

    def record_gui_action(self, action_type, **params):
        """Record a GUI action during video recording.

        Args:
            action_type: Type of action (click, scroll, input, etc.)
            **params: Additional action parameters (coordinates, duration, etc.)
        """
        if not self.recording_active:
            return

        import base64
        from io import BytesIO

        action_id = self.recording_action_counter + 1
        current_time = time.time()
        frame_number = len(self.recording_frames)

        # Process screenshot if provided
        screenshot_base64 = None
        if 'screenshot' in params and params['screenshot']:
            try:
                buffered = BytesIO()
                params['screenshot'].save(buffered, format='PNG')
                screenshot_base64 = base64.b64encode(buffered.getvalue()).decode()
            except Exception as e:
                logger.debug(f"Failed to process action screenshot: {e}")

        action_record = {
            "action_id": action_id,
            "action_type": action_type,
            "timestamp": current_time,
            "timestamp_iso": datetime.fromtimestamp(current_time).isoformat(),
            "frame_number": frame_number,
            **params
        }

        # Add screenshot if successfully processed
        if screenshot_base64:
            action_record["screenshot_base64"] = screenshot_base64

        # Store in timeline
        self.recording_action_timeline.append(action_record)

        # Map to frame number for correlation
        if frame_number not in self.recording_frame_actions:
            self.recording_frame_actions[frame_number] = []
        self.recording_frame_actions[frame_number].append(action_record)

        # Update action counter
        self.recording_action_counter = action_id

        logger.debug(f"ğŸ¯ Recorded GUI action #{action_id}: {action_type} at frame {frame_number}")

    def record_action_if_recording(self, action_type, **params):
        """Central hook for recording actions during video recording.

        This method provides a single point for all action recording logic
        and should be called throughout the codebase when actions occur.

        Args:
            action_type: Type of action (click, scroll, input, etc.)
            **params: Additional action parameters (coordinates, duration, etc.)
        """
        if self.recording_active:
            self.record_gui_action(action_type, **params)

    def _get_optimal_frame_interval(self):
        """è·å–é€‚åˆå½“å‰è®¾å¤‡çš„å¸§é—´éš”æ—¶é—´
        
        Returns:
            float: å¸§é—´éš”æ—¶é—´ï¼ˆç§’ï¼‰
        """
        # Default to 10 FPS (0.1 second interval)
        # This can be overridden by device-specific implementations
        return 0.1

